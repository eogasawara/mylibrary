{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1.5\n",
    "source(\"https://raw.githubusercontent.com/eogasawara/mylibrary/master/myBasic.R\")\n",
    "source(\"https://raw.githubusercontent.com/eogasawara/mylibrary/master/myPreprocessing.R\")\n",
    "source(\"https://raw.githubusercontent.com/eogasawara/mylibrary/master/myRegression.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: MASS\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     crim      zn        indus     chas      nox       rm        age      \n",
      "[1,] \"numeric\" \"numeric\" \"numeric\" \"integer\" \"numeric\" \"numeric\" \"numeric\"\n",
      "     dis       rad       tax       ptratio   black     lstat     medv     \n",
      "[1,] \"numeric\" \"integer\" \"numeric\" \"numeric\" \"numeric\" \"numeric\" \"numeric\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 14</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>crim</th><th scope=col>zn</th><th scope=col>indus</th><th scope=col>chas</th><th scope=col>nox</th><th scope=col>rm</th><th scope=col>age</th><th scope=col>dis</th><th scope=col>rad</th><th scope=col>tax</th><th scope=col>ptratio</th><th scope=col>black</th><th scope=col>lstat</th><th scope=col>medv</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>0.00632</td><td>18</td><td>2.31</td><td>0</td><td>0.538</td><td>6.575</td><td>65.2</td><td>4.0900</td><td>1</td><td>296</td><td>15.3</td><td>396.90</td><td>4.98</td><td>24.0</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0.02731</td><td> 0</td><td>7.07</td><td>0</td><td>0.469</td><td>6.421</td><td>78.9</td><td>4.9671</td><td>2</td><td>242</td><td>17.8</td><td>396.90</td><td>9.14</td><td>21.6</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.02729</td><td> 0</td><td>7.07</td><td>0</td><td>0.469</td><td>7.185</td><td>61.1</td><td>4.9671</td><td>2</td><td>242</td><td>17.8</td><td>392.83</td><td>4.03</td><td>34.7</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.03237</td><td> 0</td><td>2.18</td><td>0</td><td>0.458</td><td>6.998</td><td>45.8</td><td>6.0622</td><td>3</td><td>222</td><td>18.7</td><td>394.63</td><td>2.94</td><td>33.4</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.06905</td><td> 0</td><td>2.18</td><td>0</td><td>0.458</td><td>7.147</td><td>54.2</td><td>6.0622</td><td>3</td><td>222</td><td>18.7</td><td>396.90</td><td>5.33</td><td>36.2</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.02985</td><td> 0</td><td>2.18</td><td>0</td><td>0.458</td><td>6.430</td><td>58.7</td><td>6.0622</td><td>3</td><td>222</td><td>18.7</td><td>394.12</td><td>5.21</td><td>28.7</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 14\n",
       "\\begin{tabular}{r|llllllllllllll}\n",
       "  & crim & zn & indus & chas & nox & rm & age & dis & rad & tax & ptratio & black & lstat & medv\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <int> & <dbl> & <dbl> & <dbl> & <dbl> & <int> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 0.00632 & 18 & 2.31 & 0 & 0.538 & 6.575 & 65.2 & 4.0900 & 1 & 296 & 15.3 & 396.90 & 4.98 & 24.0\\\\\n",
       "\t2 & 0.02731 &  0 & 7.07 & 0 & 0.469 & 6.421 & 78.9 & 4.9671 & 2 & 242 & 17.8 & 396.90 & 9.14 & 21.6\\\\\n",
       "\t3 & 0.02729 &  0 & 7.07 & 0 & 0.469 & 7.185 & 61.1 & 4.9671 & 2 & 242 & 17.8 & 392.83 & 4.03 & 34.7\\\\\n",
       "\t4 & 0.03237 &  0 & 2.18 & 0 & 0.458 & 6.998 & 45.8 & 6.0622 & 3 & 222 & 18.7 & 394.63 & 2.94 & 33.4\\\\\n",
       "\t5 & 0.06905 &  0 & 2.18 & 0 & 0.458 & 7.147 & 54.2 & 6.0622 & 3 & 222 & 18.7 & 396.90 & 5.33 & 36.2\\\\\n",
       "\t6 & 0.02985 &  0 & 2.18 & 0 & 0.458 & 6.430 & 58.7 & 6.0622 & 3 & 222 & 18.7 & 394.12 & 5.21 & 28.7\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 14\n",
       "\n",
       "| <!--/--> | crim &lt;dbl&gt; | zn &lt;dbl&gt; | indus &lt;dbl&gt; | chas &lt;int&gt; | nox &lt;dbl&gt; | rm &lt;dbl&gt; | age &lt;dbl&gt; | dis &lt;dbl&gt; | rad &lt;int&gt; | tax &lt;dbl&gt; | ptratio &lt;dbl&gt; | black &lt;dbl&gt; | lstat &lt;dbl&gt; | medv &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 0.00632 | 18 | 2.31 | 0 | 0.538 | 6.575 | 65.2 | 4.0900 | 1 | 296 | 15.3 | 396.90 | 4.98 | 24.0 |\n",
       "| 2 | 0.02731 |  0 | 7.07 | 0 | 0.469 | 6.421 | 78.9 | 4.9671 | 2 | 242 | 17.8 | 396.90 | 9.14 | 21.6 |\n",
       "| 3 | 0.02729 |  0 | 7.07 | 0 | 0.469 | 7.185 | 61.1 | 4.9671 | 2 | 242 | 17.8 | 392.83 | 4.03 | 34.7 |\n",
       "| 4 | 0.03237 |  0 | 2.18 | 0 | 0.458 | 6.998 | 45.8 | 6.0622 | 3 | 222 | 18.7 | 394.63 | 2.94 | 33.4 |\n",
       "| 5 | 0.06905 |  0 | 2.18 | 0 | 0.458 | 7.147 | 54.2 | 6.0622 | 3 | 222 | 18.7 | 396.90 | 5.33 | 36.2 |\n",
       "| 6 | 0.02985 |  0 | 2.18 | 0 | 0.458 | 6.430 | 58.7 | 6.0622 | 3 | 222 | 18.7 | 394.12 | 5.21 | 28.7 |\n",
       "\n"
      ],
      "text/plain": [
       "  crim    zn indus chas nox   rm    age  dis    rad tax ptratio black  lstat\n",
       "1 0.00632 18 2.31  0    0.538 6.575 65.2 4.0900 1   296 15.3    396.90 4.98 \n",
       "2 0.02731  0 7.07  0    0.469 6.421 78.9 4.9671 2   242 17.8    396.90 9.14 \n",
       "3 0.02729  0 7.07  0    0.469 7.185 61.1 4.9671 2   242 17.8    392.83 4.03 \n",
       "4 0.03237  0 2.18  0    0.458 6.998 45.8 6.0622 3   222 18.7    394.63 2.94 \n",
       "5 0.06905  0 2.18  0    0.458 7.147 54.2 6.0622 3   222 18.7    396.90 5.33 \n",
       "6 0.02985  0 2.18  0    0.458 6.430 58.7 6.0622 3   222 18.7    394.12 5.21 \n",
       "  medv\n",
       "1 24.0\n",
       "2 21.6\n",
       "3 34.7\n",
       "4 33.4\n",
       "5 36.2\n",
       "6 28.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loadlibrary(\"MASS\")\n",
    "data(Boston)\n",
    "print(t(sapply(Boston, class)))\n",
    "head(Boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for performance issues, you can use matrix\n",
    "Boston <- as.matrix(Boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building samples (training and testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing dataset for random sampling\n",
    "set.seed(1)\n",
    "sr <- sample_random()\n",
    "sr <- train_test(sr, Boston)\n",
    "boston_train = sr$train\n",
    "boston_test = sr$test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General function for testing regression methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test <- function(model, boston_train, boston_test) {\n",
    "  print(class(model)[1])\n",
    "\n",
    "  model <- fit(model, boston_train)\n",
    "  \n",
    "  train_prediction <- predict(model, boston_train)\n",
    "  boston_train_predictand = boston_train[,\"medv\"]\n",
    "  train_eval <- evaluation.regression(boston_train_predictand, train_prediction)\n",
    "  print(train_eval$metrics)\n",
    "\n",
    "  test_prediction <- predict(model, boston_test)\n",
    "  boston_test_predictand = boston_test[,\"medv\"]\n",
    "  test_eval <- evaluation.regression(boston_test_predictand, test_prediction)\n",
    "  print(test_eval$metrics)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "Training the model, presenting the level of adjustment, quality of prediction, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"regression_dtree\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: tree\n",
      "\n",
      "regression_dtree,fit.regression_dtree,0.056,\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       mse     smape\n",
      "1 12.68065 0.1345098\n",
      "       mse     smape\n",
      "1 29.38142 0.1642396\n"
     ]
    }
   ],
   "source": [
    "  train_test(regression_dtree(\"medv\"), boston_train, boston_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"regression_rf\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: randomForest\n",
      "\n",
      "randomForest 4.6-14\n",
      "\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "regression_rf,fit.regression_rf,0.009,mtry=7,ntree=30\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       mse     smape\n",
      "1 1.818252 0.0450991\n",
      "       mse     smape\n",
      "1 12.91163 0.1165387\n"
     ]
    }
   ],
   "source": [
    "# do not set mtry and ntree for hyperparameter optimization\n",
    "# you can also set a range for them\n",
    "  train_test(regression_rf(\"medv\", mtry=7,ntree=30), boston_train, boston_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks - MLP using nnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"regression_mlp\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: nnet\n",
      "\n",
      "regression_mlp,fit.regression_mlp,0.008,size=5,decay=0.54\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       mse      smape\n",
      "1 5.860308 0.08783845\n",
      "       mse     smape\n",
      "1 15.89314 0.1341734\n"
     ]
    }
   ],
   "source": [
    "# do not set neurons and decay for hyperparameter optimization\n",
    "# you can also set a range for them\n",
    "train_test(regression_mlp(\"medv\", size=5,decay=0.54), boston_train, boston_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a SVM with RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"regression_svm\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: e1071\n",
      "\n",
      "regression_svm,fit.regression_svm,0.015,epsilon=0.2,cost=40.000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       mse     smape\n",
      "1 2.855767 0.0700268\n",
      "       mse     smape\n",
      "1 14.65598 0.1363336\n"
     ]
    }
   ],
   "source": [
    "#do not set epsilon, cost, and  kernel for hyperparameter optimization\n",
    "# you can also set a range for them\n",
    "train_test(regression_svm(\"medv\", epsilon=0.2,cost=40.000), boston_train, boston_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"regression_knn\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: FNN\n",
      "\n",
      "regression_knn,fit.regression_knn,0.005,k=5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       mse    smape\n",
      "1 27.02782 0.155995\n",
      "      mse     smape\n",
      "1 26.9483 0.1791238\n"
     ]
    }
   ],
   "source": [
    "# do not set k for hyperparameter optimization\n",
    "# you can also set a range for it\n",
    "train_test(regression_knn(\"medv\", k=5), boston_train, boston_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural networks (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"regression_cnn\"\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in spec$dense_features(): Only available after fitting the feature_spec.\n",
     "output_type": "error",
     "traceback": [
      "Error in spec$dense_features(): Only available after fitting the feature_spec.\nTraceback:\n",
      "1. train_test(regression_cnn(\"medv\", neurons = 32, epochs = 200), \n .     boston_train, boston_test)",
      "2. fit(model, boston_train)   # at line 4 of file <text>",
      "3. fit.regression_cnn(model, boston_train)",
      "4. tune.regression(x = x, y = y, ranges = ranges, fit.func = internal_fit.regression_cnn)",
      "5. do.call(fit.func, params)",
      "6. (function (x, y, neurons, epochs, ...) \n . {\n .     data <- adjust.data.frame(x)\n .     data$y <- y\n .     spec <- feature_spec(data, y ~ .) %>% step_numeric_column(all_numeric(), \n .         normalizer_fn = scaler_standard()) %>% fit()\n .     input <- layer_input_from_dataset(data %>% dplyr::select(-y))\n .     output <- input %>% layer_dense_features(dense_features(spec)) %>% \n .         layer_dense(units = neurons, activation = \"relu\") %>% \n .         layer_dense(units = neurons, activation = \"relu\") %>% \n .         layer_dense(units = 1)\n .     model <- keras_model(input, output)\n .     model %>% compile(loss = \"mse\", optimizer = optimizer_rmsprop(), \n .         metrics = list(\"mean_absolute_error\"))\n .     history <- model %>% fit(x = data %>% dplyr::select(-y), \n .         y = data$y, epochs = epochs, validation_split = 0.2, \n .         verbose = 0)\n .     return(model)\n . })(x = structure(list(crim = c(0.10959, 0.28392, 2.01019, 0.32543, \n . 25.9406, 4.34879, 0.06466, 0.09065, 3.1636, 0.05602, 0.07503, \n . 5.82401, 0.05059, 0.10469, 3.83684, 15.1772, 0.06724, 0.52014, \n . 0.06617, 0.05646, 0.21719, 0.09744, 0.1396, 0.0456, 4.55587, \n . 2.24236, 0.04297, 0.10574, 15.8744, 0.0566, 37.6619, 6.65492, \n . 0.0459, 0.05497, 73.5341, 0.19186, 0.18337, 0.12744, 7.02259, \n . 0.10793, 24.8017, 14.0507, 0.7258, 0.15936, 15.288, 0.02498, \n . 0.12816, 0.06899, 0.02763, 2.3139, 0.75026, 18.4982, 0.19657, \n . 0.04666, 9.82349, 0.17505, 13.9134, 0.14103, 8.15174, 0.21038, \n . 1.42502, 0.62976, 0.88125, 0.12269, 14.2362, 0.85204, 0.13642, \n . 0.44178, 0.08664, 6.53876, 0.21161, 0.22438, 0.04819, 7.52601, \n . 11.1604, 0.22876, 0.04544, 0.09378, 0.12932, 5.73116, 0.06664, \n . 0.03049, 0.07978, 0.26363, 0.03551, 5.20177, 0.77299, 0.2909, \n . 0.21409, 67.9208, 0.35809, 7.83932, 0.13117, 0.1, 1.38799, 5.66637, \n . 2.33099, 0.01965, 0.11432, 2.77974, 4.83567, 4.81213, 0.03306, \n . 0.15098, 0.03113, 18.811, 0.1712, 0.1265, 0.6147, 8.49213, 0.25356, \n . 0.08873, 18.0846, 14.3337, 0.35233, 0.04527, 0.17783, 0.03705, \n . 3.32105, 0.00906, 2.44953, 0.22927, 0.0351, 0.08199, 0.98843, \n . 0.06588, 0.14052, 6.39312, 0.31533, 0.26838, 9.72418, 1.83377, \n . 0.1415, 0.00632, 11.8123, 0.08707, 6.44405, 0.01501, 0.17134, \n . 0.57529, 0.03615, 0.14932, 0.05735, 0.30347, 12.0482, 0.04301, \n . 0.17899, 0.05561, 0.25387, 8.71675, 0.10612, 0.19133, 0.05515, \n . 0.05479, 0.33983, 0.08244, 0.11069, 0.97617, 3.77498, 5.82115, \n . 13.3598, 0.0536, 9.96654, 25.0461, 0.01951, 11.0874, 2.81838, \n . 0.15038, 0.10153, 0.07013, 0.12083, 0.02187, 0.80271, 0.1146, \n . 1.13081, 0.09178, 0.52058, 0.07896, 0.62739, 8.20058, 0.55007, \n . 0.07244, 0.03932, 0.07165, 1.49632, 5.29305, 0.22969, 0.16439, \n . 10.6718, 0.29819, 0.54452, 0.16902, 12.8023, 13.5222, 0.24103, \n . 0.29916, 0.02543, 0.01301, 0.03466, 0.37578, 0.38735, 0.59005, \n . 0.03359, 0.06417, 0.05372, 38.3518, 6.96215, 4.26131, 0.13158, \n . 11.9511, 0.21977, 0.01096, 0.36894, 0.15876, 14.4208, 1.80028, \n . 0.26169, 0.12329, 0.33147, 7.75223, 0.09164, 0.67191, 41.5292, \n . 0.63796, 0.17171, 1.19294, 1.61282, 0.03041, 3.56868, 0.08308, \n . 1.12658, 0.05023, 2.37857, 5.58107, 0.537, 0.95577, 14.3337, \n . 2.36862, 0.34109, 0.10328, 0.05644, 0.04203, 0.03445, 0.03961, \n . 0.11329, 45.7461, 0.03578, 9.32909, 4.22239, 12.2472, 15.0234, \n . 0.22188, 28.6558, 0.06129, 0.26938, 0.06211, 0.13587, 0.1403, \n . 0.04462, 0.11504, 7.67202, 5.70818, 8.79212, 0.01311, 0.03871, \n . 0.16211, 0.03768, 0.02899, 0.44791, 0.05425, 0.01778, 0.5405, \n . 0.15086, 0.14866, 5.66998, 10.8342, 0.02731, 11.5779, 0.34006, \n . 0.0187, 2.924, 0.08221, 3.53501, 0.09103, 0.04011, 0.11425, 9.39063, \n . 0.27957, 11.1081, 0.19073, 8.26725, 0.13914, 0.0795, 0.03659, \n . 1.6566, 0.05789, 0.25199, 0.11132, 5.87205, 0.57834, 0.03537, \n . 0.0578, 1.46336, 9.51363, 0.19539, 5.09017, 0.07875, 0.06076, \n . 3.8497, 0.0837, 1.27346, 6.28807, 0.2498, 4.03841, 13.0751, 0.7857, \n . 0.05302, 0.40771, 0.10084, 0.03502, 7.99248, 0.17446, 0.1029, \n . 4.75237, 0.52693, 0.04113, 9.18702, 0.28955, 0.02009, 2.73397, \n . 10.0623, 0.02729, 2.15505, 0.01381, 0.25915, 0.47547, 0.03237, \n . 0.09068, 0.49298, 0.01709, 0.13262, 0.01439, 7.40389, 1.23247, \n . 2.44668, 0.66351, 0.40202, 0.13058, 0.08187, 0.51183, 0.07022, \n . 1.51902, 0.61154, 0.08265, 0.7842, 8.05579, 9.2323, 0.04684, \n . 1.35472, 19.6091, 1.34284, 9.33889, 0.09849, 4.87141, 1.25179, \n . 5.69175, 0.14231, 3.69695, 0.07886, 0.08826, 4.66883, 0.15445, \n . 0.12579, 0.01432, 5.44114, 0.22212, 0.04417, 1.15172, 1.62864, \n . 0.19802, 1.05393, 7.05042, 0.23912, 0.06642, 51.1358, 0.32982, \n . 3.67822, 0.03584, 4.89822, 0.14455, 0.62356, 0.04294, 0.06162, \n . 10.233, 4.42228, 0.06905, 0.82526, 0.09604, 0.41238, 0.0136, \n . 0.10008, 0.20746, 4.54192, 13.6781), zn = c(0, 0, 0, 0, 0, 0, \n . 70, 20, 0, 0, 33, 0, 0, 40, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, \n . 0, 52.5, 0, 0, 0, 0, 0, 52.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n . 0, 0, 12.5, 0, 75, 0, 0, 0, 22, 80, 0, 0, 0, 0, 0, 20, 0, 0, \n . 0, 0, 0, 0, 0, 0, 45, 0, 0, 0, 80, 0, 0, 0, 0, 12.5, 0, 0, 0, \n . 55, 40, 0, 25, 0, 0, 0, 22, 0, 0, 0, 0, 34, 0, 0, 0, 80, 0, 0, \n . 0, 0, 0, 0, 0, 0, 0, 25, 0, 0, 0, 21, 0, 0, 0, 0, 0, 20, 0, 90, \n . 0, 0, 95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 0, 0, 0, 90, 0, 0, \n . 80, 25, 0, 0, 0, 80, 0, 70, 0, 0, 30, 22, 33, 33, 22, 30, 0, \n . 0, 0, 0, 0, 21, 0, 0, 17.5, 0, 0, 0, 0, 0, 0, 60, 0, 20, 0, 0, \n . 0, 0, 0, 0, 20, 60, 0, 0, 0, 0, 0, 22, 0, 0, 0, 0, 0, 0, 0, 20, \n . 55, 35, 35, 0, 0, 0, 75, 0, 0, 0, 0, 0, 0, 0, 0, 55, 22, 0, 0, \n . 0, 0, 0, 0, 0, 0, 0, 0, 0, 25, 0, 0, 0, 0, 0, 0, 35, 0, 0, 0, \n . 0, 0, 0, 0, 25, 40, 28, 82.5, 0, 30, 0, 20, 0, 0, 0, 0, 20, 0, \n . 20, 0, 40, 0, 22, 25, 0, 0, 0, 0, 90, 52.5, 20, 80, 40, 0, 0, \n . 95, 20, 0, 0, 0, 0, 0, 0, 0, 85, 0, 22, 0, 0, 80, 0, 0, 0, 0, \n . 22, 0, 0, 60, 25, 0, 12.5, 0, 0, 0, 20, 34, 0, 0, 0, 0, 0, 45, \n . 0, 0, 45, 0, 0, 0, 0, 0, 20, 0, 0, 0, 80, 0, 0, 30, 0, 0, 25, \n . 0, 0, 95, 0, 0, 0, 0, 80, 0, 0, 0, 45, 0, 90, 0, 60, 0, 0, 0, \n . 20, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n . 0, 0, 0, 80, 0, 0, 25, 45, 100, 0, 0, 70, 0, 0, 0, 0, 0, 0, 0, \n . 0, 0, 0, 80, 0, 12.5, 0, 28, 0, 0, 0, 0, 20, 40, 0, 75, 0, 0, \n . 0, 0), indus = c(11.93, 7.38, 19.58, 21.89, 18.1, 18.1, 2.24, \n . 6.96, 18.1, 2.46, 2.18, 18.1, 4.49, 6.41, 18.1, 18.1, 3.24, 3.97, \n . 3.24, 12.83, 10.59, 5.96, 8.56, 13.89, 18.1, 19.58, 5.32, 27.74, \n . 18.1, 3.41, 18.1, 18.1, 5.32, 5.19, 18.1, 7.38, 27.74, 6.91, \n . 18.1, 8.56, 18.1, 18.1, 8.14, 6.91, 18.1, 1.89, 6.07, 25.65, \n . 2.95, 19.58, 8.14, 18.1, 5.86, 1.52, 18.1, 5.96, 18.1, 13.92, \n . 18.1, 3.33, 19.58, 8.14, 21.89, 6.91, 18.1, 8.14, 10.59, 6.2, \n . 3.44, 18.1, 8.56, 9.69, 3.64, 18.1, 18.1, 8.56, 3.24, 7.87, 13.92, \n . 18.1, 4.05, 3.78, 6.41, 8.56, 4.86, 18.1, 8.14, 21.89, 5.86, \n . 18.1, 6.2, 18.1, 8.56, 6.09, 8.14, 18.1, 19.58, 1.76, 8.56, 19.58, \n . 18.1, 18.1, 5.19, 10.01, 4.39, 18.1, 8.56, 5.13, 6.2, 18.1, 9.9, \n . 5.64, 18.1, 18.1, 21.89, 11.93, 9.69, 3.33, 19.58, 2.97, 19.58, \n . 6.91, 2.68, 13.92, 8.14, 2.46, 10.59, 18.1, 6.2, 9.69, 18.1, \n . 19.58, 6.91, 2.31, 18.1, 12.83, 18.1, 1.21, 10.01, 6.2, 4.95, \n . 5.13, 4.49, 7.38, 18.1, 1.91, 9.69, 2.24, 6.91, 18.1, 4.93, 5.86, \n . 2.18, 2.18, 5.86, 4.93, 13.89, 21.89, 18.1, 18.1, 18.1, 5.64, \n . 18.1, 18.1, 1.38, 18.1, 18.1, 25.65, 12.83, 13.89, 2.89, 2.93, \n . 8.14, 6.96, 8.14, 4.05, 6.2, 12.83, 8.14, 18.1, 3.97, 1.69, 3.41, \n . 25.65, 19.58, 18.1, 10.59, 5.86, 18.1, 6.2, 21.89, 25.65, 18.1, \n . 18.1, 7.38, 6.96, 3.78, 1.52, 6.06, 10.59, 25.65, 21.89, 2.95, \n . 5.96, 13.92, 18.1, 18.1, 18.1, 10.01, 18.1, 6.91, 2.25, 5.86, \n . 10.81, 18.1, 19.58, 9.9, 10.01, 6.2, 18.1, 10.81, 8.14, 18.1, \n . 8.14, 5.13, 21.89, 8.14, 5.19, 18.1, 2.46, 19.58, 6.06, 18.1, \n . 18.1, 6.2, 8.14, 18.1, 19.58, 7.38, 5.13, 6.41, 15.04, 2.03, \n . 5.19, 4.93, 18.1, 3.33, 18.1, 18.1, 18.1, 18.1, 6.96, 18.1, 3.33, \n . 9.9, 1.25, 10.59, 5.86, 4.86, 2.89, 18.1, 18.1, 18.1, 1.22, 5.32, \n . 6.96, 1.52, 1.25, 6.2, 4.05, 1.47, 3.97, 27.74, 8.56, 18.1, 18.1, \n . 7.07, 18.1, 21.89, 4.15, 19.58, 5.86, 19.58, 2.46, 1.52, 13.89, \n . 18.1, 9.69, 18.1, 5.86, 18.1, 4.05, 1.69, 4.86, 19.58, 6.07, \n . 10.59, 27.74, 18.1, 3.97, 6.09, 2.46, 19.58, 18.1, 10.81, 18.1, \n . 3.44, 11.93, 18.1, 3.44, 19.58, 18.1, 21.89, 18.1, 18.1, 3.97, \n . 3.41, 6.2, 10.01, 4.95, 18.1, 10.59, 4.93, 18.1, 6.2, 4.86, 18.1, \n . 10.59, 2.68, 19.58, 18.1, 7.07, 19.58, 0.46, 21.89, 9.9, 2.18, \n . 3.44, 9.9, 2.02, 8.56, 2.93, 18.1, 8.14, 19.58, 3.97, 9.9, 10.01, \n . 2.89, 6.2, 4.05, 19.58, 3.97, 13.92, 8.14, 18.1, 18.1, 3.41, \n . 8.14, 18.1, 19.58, 18.1, 25.65, 18.1, 8.14, 18.1, 10.01, 18.1, \n . 4.95, 10.81, 18.1, 5.13, 3.44, 1.32, 18.1, 10.01, 2.24, 8.14, \n . 21.89, 10.59, 8.14, 18.1, 9.69, 4.05, 18.1, 21.89, 18.1, 3.37, \n . 18.1, 7.87, 6.2, 15.04, 4.39, 18.1, 18.1, 2.18, 3.97, 6.41, 6.2, \n . 4, 2.46, 27.74, 18.1, 18.1), chas = c(0, 0, 0, 0, 0, 0, 0, 1, \n . 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, \n . 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n . 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, \n . 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, \n . 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n . 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, \n . 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n . 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n . 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n . 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n . 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, \n . 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, \n . 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, \n . 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n . 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, \n . 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n . 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n . 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n . 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), nox = c(0.573, \n . 0.493, 0.605, 0.624, 0.679, 0.58, 0.4, 0.464, 0.655, 0.488, 0.472, \n . 0.532, 0.449, 0.447, 0.77, 0.74, 0.46, 0.647, 0.46, 0.437, 0.489, \n . 0.499, 0.52, 0.55, 0.718, 0.605, 0.405, 0.609, 0.671, 0.489, \n . 0.679, 0.713, 0.405, 0.515, 0.679, 0.493, 0.609, 0.448, 0.718, \n . 0.52, 0.693, 0.597, 0.538, 0.448, 0.671, 0.518, 0.409, 0.581, \n . 0.428, 0.605, 0.538, 0.668, 0.431, 0.404, 0.671, 0.499, 0.713, \n . 0.437, 0.7, 0.4429, 0.871, 0.538, 0.624, 0.448, 0.693, 0.538, \n . 0.489, 0.504, 0.437, 0.631, 0.52, 0.585, 0.392, 0.713, 0.74, \n . 0.52, 0.46, 0.524, 0.437, 0.532, 0.51, 0.484, 0.447, 0.52, 0.426, \n . 0.77, 0.538, 0.624, 0.431, 0.693, 0.507, 0.655, 0.52, 0.433, \n . 0.538, 0.74, 0.871, 0.385, 0.52, 0.871, 0.583, 0.713, 0.515, \n . 0.547, 0.442, 0.597, 0.52, 0.453, 0.507, 0.584, 0.544, 0.439, \n . 0.679, 0.614, 0.624, 0.573, 0.585, 0.4429, 0.871, 0.4, 0.605, \n . 0.448, 0.4161, 0.437, 0.538, 0.488, 0.489, 0.584, 0.504, 0.585, \n . 0.74, 0.605, 0.448, 0.538, 0.718, 0.437, 0.584, 0.401, 0.547, \n . 0.507, 0.411, 0.453, 0.449, 0.493, 0.614, 0.413, 0.585, 0.4, \n . 0.448, 0.693, 0.428, 0.431, 0.472, 0.472, 0.431, 0.428, 0.55, \n . 0.624, 0.655, 0.713, 0.693, 0.439, 0.74, 0.693, 0.4161, 0.718, \n . 0.532, 0.581, 0.437, 0.55, 0.445, 0.401, 0.538, 0.464, 0.538, \n . 0.51, 0.507, 0.437, 0.538, 0.713, 0.647, 0.411, 0.489, 0.581, \n . 0.871, 0.7, 0.489, 0.431, 0.74, 0.504, 0.624, 0.581, 0.74, 0.631, \n . 0.493, 0.464, 0.484, 0.442, 0.4379, 0.489, 0.581, 0.624, 0.428, \n . 0.499, 0.437, 0.693, 0.7, 0.77, 0.547, 0.659, 0.448, 0.389, 0.431, \n . 0.413, 0.74, 0.605, 0.544, 0.547, 0.507, 0.713, 0.413, 0.538, \n . 0.693, 0.538, 0.453, 0.624, 0.538, 0.515, 0.58, 0.488, 0.871, \n . 0.4379, 0.583, 0.713, 0.504, 0.538, 0.7, 0.871, 0.493, 0.453, \n . 0.447, 0.464, 0.415, 0.515, 0.428, 0.693, 0.4429, 0.713, 0.77, \n . 0.584, 0.614, 0.464, 0.597, 0.4429, 0.544, 0.429, 0.489, 0.431, \n . 0.426, 0.445, 0.693, 0.532, 0.584, 0.403, 0.405, 0.464, 0.404, \n . 0.429, 0.507, 0.51, 0.403, 0.575, 0.609, 0.52, 0.631, 0.679, \n . 0.469, 0.7, 0.624, 0.429, 0.605, 0.431, 0.871, 0.488, 0.404, \n . 0.55, 0.74, 0.585, 0.668, 0.431, 0.668, 0.51, 0.411, 0.426, 0.871, \n . 0.409, 0.489, 0.609, 0.693, 0.575, 0.433, 0.488, 0.605, 0.713, \n . 0.413, 0.713, 0.437, 0.573, 0.77, 0.437, 0.605, 0.74, 0.624, \n . 0.532, 0.58, 0.647, 0.489, 0.507, 0.547, 0.411, 0.7, 0.489, 0.428, \n . 0.713, 0.504, 0.426, 0.7, 0.489, 0.4161, 0.871, 0.584, 0.469, \n . 0.871, 0.422, 0.624, 0.544, 0.458, 0.437, 0.544, 0.41, 0.52, \n . 0.401, 0.597, 0.538, 0.871, 0.647, 0.544, 0.547, 0.445, 0.507, \n . 0.51, 0.605, 0.647, 0.437, 0.538, 0.584, 0.631, 0.489, 0.538, \n . 0.671, 0.605, 0.679, 0.581, 0.614, 0.538, 0.583, 0.547, 0.718, \n . 0.411, 0.413, 0.713, 0.453, 0.437, 0.411, 0.713, 0.547, 0.4, \n . 0.538, 0.624, 0.489, 0.538, 0.614, 0.585, 0.51, 0.597, 0.624, \n . 0.77, 0.398, 0.631, 0.524, 0.507, 0.464, 0.442, 0.614, 0.584, \n . 0.458, 0.647, 0.447, 0.504, 0.41, 0.488, 0.609, 0.77, 0.74), \n .     rm = c(6.794, 5.708, 7.929, 6.431, 5.304, 6.167, 6.345, 5.92, \n .     5.759, 7.831, 7.42, 6.242, 6.389, 7.267, 6.251, 6.152, 6.333, \n .     8.398, 5.868, 6.232, 5.807, 5.841, 6.167, 5.888, 3.561, 5.854, \n .     6.565, 5.983, 6.545, 7.007, 6.202, 6.317, 6.315, 5.985, 5.957, \n .     6.431, 5.414, 6.77, 6.006, 6.195, 5.349, 6.657, 5.727, 6.211, \n .     6.649, 6.54, 5.885, 5.87, 6.595, 5.88, 5.924, 4.138, 6.226, \n .     7.107, 6.794, 5.966, 6.208, 5.79, 5.39, 6.812, 6.51, 5.949, \n .     5.637, 6.069, 6.343, 5.965, 5.891, 6.552, 7.178, 7.016, 6.137, \n .     6.027, 6.108, 6.417, 6.629, 6.405, 6.144, 5.889, 6.678, 7.061, \n .     6.546, 6.874, 6.482, 6.229, 6.167, 6.127, 6.495, 6.174, 6.438, \n .     5.683, 6.951, 6.209, 6.127, 6.982, 5.95, 6.219, 5.186, 6.23, \n .     6.781, 4.903, 5.905, 6.701, 6.059, 6.021, 6.014, 4.628, 5.836, \n .     6.762, 6.618, 6.348, 5.705, 5.963, 6.434, 6.229, 6.454, 6.12, \n .     5.569, 6.968, 5.403, 7.088, 6.402, 6.03, 7.853, 6.009, 5.813, \n .     7.765, 6.375, 6.162, 8.266, 5.794, 6.406, 7.802, 6.169, 6.575, \n .     6.824, 6.14, 6.425, 7.923, 5.928, 8.337, 6.63, 5.741, 6.63, \n .     6.312, 5.648, 5.663, 5.67, 7.041, 5.399, 6.471, 6.095, 5.605, \n .     7.236, 6.616, 6.108, 6.481, 5.951, 5.757, 5.952, 6.513, 5.887, \n .     6.511, 6.485, 5.987, 7.104, 6.411, 5.762, 5.856, 6.279, 6.642, \n .     8.069, 6.8, 5.456, 6.538, 5.713, 6.416, 6.631, 6.273, 5.834, \n .     5.936, 7.206, 5.884, 6.405, 6.004, 5.404, 6.051, 6.326, 6.433, \n .     6.459, 7.686, 6.151, 5.986, 5.854, 3.863, 6.083, 5.856, 6.696, \n .     7.241, 6.031, 5.404, 5.613, 6.372, 7.024, 5.933, 6.549, 5.453, \n .     5.713, 6.112, 6.176, 5.608, 5.602, 6.453, 8.259, 5.961, 6.461, \n .     5.877, 6.023, 5.913, 8.247, 6.301, 6.065, 5.813, 5.531, 6.096, \n .     5.966, 6.326, 6.096, 5.895, 6.437, 5.604, 5.012, 5.706, 5.871, \n .     6.436, 5.981, 6.047, 4.88, 4.926, 6.415, 5.927, 6.758, 6.442, \n .     6.162, 6.037, 6.897, 4.519, 7.82, 6.185, 5.803, 5.837, 5.304, \n .     7.691, 5.155, 7.645, 6.266, 6.49, 6.064, 6.487, 6.619, 6.163, \n .     5.747, 6.75, 5.565, 7.249, 6.209, 6.24, 7.274, 6.939, 6.726, \n .     6.315, 7.135, 7.47, 5.454, 6.727, 6.683, 6.782, 6.421, 5.036, \n .     6.458, 6.516, 6.101, 6.957, 6.152, 7.155, 7.287, 6.373, 5.627, \n .     5.926, 4.906, 6.718, 5.875, 5.572, 6.579, 6.302, 6.122, 5.878, \n .     5.783, 5.983, 6.405, 8.297, 6.59, 6.98, 7.489, 6.728, 6.245, \n .     6.297, 6.782, 6.976, 6.395, 7.185, 6.25, 6.341, 5.857, 6.229, \n .     5.713, 7.014, 7.079, 6.164, 6.715, 6.861, 5.52, 5.96, 6.358, \n .     6.525, 8.725, 6.727, 5.536, 5.412, 8.034, 5.597, 6.833, 7.185, \n .     5.628, 7.875, 5.693, 6.113, 6.998, 6.951, 6.635, 6.728, 5.851, \n .     6.604, 5.617, 6.142, 5.272, 7.333, 6.382, 5.872, 7.82, 7.358, \n .     6.02, 8.375, 8.704, 6.127, 5.99, 5.427, 6.216, 6.417, 6.072, \n .     7.313, 6.066, 6.38, 5.879, 6.484, 5.57, 6.114, 6.254, 4.963, \n .     7.148, 6.417, 5.976, 6.145, 6.556, 6.816, 6.655, 6.092, 6.871, \n .     5.701, 5.019, 6.182, 5.935, 6.103, 6.019, 6.86, 5.757, 5.822, \n .     5.362, 6.29, 4.97, 6.172, 6.879, 6.249, 5.898, 6.185, 6.003, \n .     7.147, 7.327, 6.854, 7.163, 5.888, 6.563, 5.093, 6.398, 5.935\n .     ), age = c(89.3, 74.3, 96.2, 98.8, 89.1, 84, 20.1, 61.5, \n .     48.2, 53.6, 71.9, 64.7, 48, 49, 91.1, 100, 17.2, 91.5, 25.8, \n .     53.7, 53.8, 61.4, 90, 56, 87.9, 91.8, 22.9, 98.8, 99.1, 86.3, \n .     78.7, 83, 45.6, 45.4, 100, 14.7, 98.3, 2.9, 95.3, 54.4, 96, \n .     100, 69.5, 6.5, 93.3, 59.7, 33, 69.7, 21.8, 97.3, 94.1, 100, \n .     79.2, 36.6, 98.8, 30.2, 95, 58, 98.9, 32.2, 100, 61.8, 94.7, \n .     40, 100, 89.2, 22.3, 21.4, 26.3, 97.5, 87.4, 79.7, 32, 98.3, \n .     94.6, 85.4, 32.2, 39, 31.1, 77, 33.1, 28.1, 32.1, 91.2, 46.7, \n .     83.4, 94.4, 93.6, 8.9, 100, 88.5, 65.4, 85.2, 17.7, 82, 100, \n .     93.8, 31.5, 71.3, 97.8, 53.2, 90, 37.3, 82.6, 48.5, 100, \n .     91.9, 43.4, 80.8, 86.1, 77.7, 45.7, 100, 88, 98.4, 76.7, \n .     73.5, 37.2, 100, 20.8, 95.2, 85.5, 33.2, 42.3, 100, 83.3, \n .     32.3, 97.4, 78.3, 70.6, 97.2, 98.2, 6.6, 65.2, 76.5, 45.8, \n .     74.8, 24.8, 88.2, 73.3, 23.4, 66.2, 56.1, 28.9, 87.6, 21.9, \n .     28.8, 10, 95.3, 98.8, 65.1, 70.2, 41.1, 58.1, 34.9, 18.5, \n .     93.8, 98.4, 84.7, 89.9, 94.7, 21.1, 100, 100, 59.5, 100, \n .     40.3, 97, 74.5, 85.1, 76, 9.9, 36.6, 58.7, 94.1, 84.1, 76.5, \n .     6, 56.5, 80.3, 91.6, 18.5, 73.9, 84.1, 100, 82.5, 52.5, 49.1, \n .     94.8, 17, 97.9, 88.4, 96.6, 100, 43.7, 42.1, 56.4, 49.3, \n .     23.3, 88.6, 95.6, 97.9, 15.8, 68.2, 51, 100, 97, 81.3, 72.5, \n .     100, 62, 31.9, 8.4, 17.5, 93.3, 79.2, 90.4, 92.9, 70.4, 83.7, \n .     7.8, 90.3, 85.4, 84.5, 93.4, 97.7, 96.9, 59.6, 75, 89.8, \n .     88, 28.4, 41.9, 87.9, 68.1, 88.8, 100, 95.7, 40.1, 47.2, \n .     32.9, 53.6, 38.4, 34.5, 54.3, 100, 64.5, 98.7, 89, 59.7, \n .     97.3, 51.8, 100, 49.7, 82.8, 44.4, 59.1, 13, 70.4, 69.6, \n .     98.9, 74.9, 70.6, 21.9, 31.3, 16.3, 38.3, 34.5, 66.5, 73.4, \n .     13.9, 52.6, 92.7, 79.9, 96.8, 90.8, 78.9, 97, 98.9, 27.7, \n .     93, 6.8, 82.6, 92.2, 34.1, 92.4, 93.9, 42.6, 100, 17.5, 89.6, \n .     88.5, 35.9, 32.2, 97.3, 21.4, 72.7, 83.5, 96, 67, 40.4, 58.4, \n .     90.8, 94.1, 6.2, 91.8, 41.1, 91, 91, 38.9, 92.6, 96.4, 98.2, \n .     90.7, 56.7, 84.6, 63.1, 91.3, 81.6, 27.9, 100, 92.1, 52.9, \n .     86.5, 83, 33.5, 100, 9.8, 31.9, 94.9, 94.3, 61.1, 100, 32, \n .     96, 58.8, 45.8, 21.5, 82.5, 36.1, 96.7, 18.8, 97.9, 91.7, \n .     94, 100, 67.2, 73.1, 36.9, 71.6, 47.2, 93.9, 86.9, 18.4, \n .     81.7, 95.4, 100, 66.1, 100, 97.9, 100, 95.6, 95.8, 93.6, \n .     98.1, 79.8, 84.2, 91.4, 27.7, 6.6, 87.9, 29.2, 29.1, 40.5, \n .     98.2, 95.4, 47.4, 95, 100, 42.4, 29.3, 85.1, 65.3, 74.4, \n .     100, 95.4, 96.2, 17.8, 100, 96.1, 77.7, 77.3, 52.3, 96.7, \n .     94.5, 54.2, 94.5, 42.8, 79.9, 47.6, 95.6, 98, 88, 87.9), \n .     dis = c(2.3889, 4.7211, 2.0459, 1.8125, 1.6475, 3.0334, 7.8278, \n .     3.9175, 3.0665, 3.1992, 3.0992, 3.4242, 4.7794, 4.7872, 2.2955, \n .     1.9142, 5.2146, 2.2885, 5.2146, 5.0141, 3.6526, 3.3779, 2.421, \n .     3.1121, 1.6132, 2.422, 7.3172, 1.8681, 1.5192, 3.4217, 1.8629, \n .     2.7344, 7.3172, 4.8122, 1.8026, 5.4159, 1.7554, 5.7209, 1.8746, \n .     2.7778, 1.7028, 1.5275, 3.7965, 5.7209, 1.3449, 6.2669, 6.498, \n .     2.2577, 5.4011, 2.3887, 4.3996, 1.137, 8.0555, 7.309, 1.358, \n .     3.8473, 2.2222, 6.32, 1.7281, 4.1007, 1.7659, 4.7075, 1.9799, \n .     5.7209, 1.5741, 4.0123, 3.9454, 3.3751, 6.4798, 1.2024, 2.7147, \n .     2.4982, 9.2203, 2.185, 2.1247, 2.7147, 5.8736, 5.4509, 5.9604, \n .     3.4106, 3.1323, 6.4654, 4.1403, 2.5451, 5.4007, 2.7227, 4.4547, \n .     1.6119, 7.3967, 1.4254, 2.8617, 2.9634, 2.1224, 5.4917, 3.99, \n .     2.0048, 1.5296, 9.0892, 2.8561, 1.3459, 3.1523, 2.5975, 4.8122, \n .     2.7474, 8.0136, 1.5539, 2.211, 7.9809, 3.2721, 2.0527, 3.945, \n .     6.8147, 1.8347, 1.9512, 1.8498, 2.2875, 2.3999, 5.2447, 1.3216, \n .     7.3073, 2.2625, 5.6894, 5.118, 5.5027, 4.0952, 2.741, 3.9454, \n .     2.206, 2.8944, 2.8927, 2.0651, 2.0407, 5.7209, 4.09, 1.794, \n .     4.0905, 2.2004, 5.885, 2.4631, 3.8384, 5.1167, 7.2254, 4.4377, \n .     5.4159, 1.9512, 10.5857, 2.7986, 7.8278, 5.87, 1.7257, 6.3361, \n .     7.9549, 4.022, 3.37, 8.0555, 6.1899, 2.8893, 2.346, 2.8715, \n .     2.8016, 1.7821, 6.8147, 1.9784, 1.5888, 9.2229, 1.8589, 4.0983, \n .     1.9444, 4.0522, 3.4211, 3.4952, 6.2196, 3.7965, 3.9175, 4.233, \n .     2.6463, 4.148, 4.2515, 4.4986, 2.7792, 1.9301, 10.7103, 3.0921, \n .     2.1974, 1.5916, 2.1678, 4.3549, 7.8265, 1.9879, 3.3751, 1.6687, \n .     1.9929, 1.8956, 1.5106, 5.4159, 4.429, 5.7321, 7.0379, 6.6407, \n .     3.665, 1.7572, 2.3274, 5.4011, 3.3603, 5.9604, 1.4896, 1.9265, \n .     2.5091, 2.7301, 1.2852, 6.0877, 7.3073, 8.9067, 5.2873, 2.0026, \n .     2.4259, 2.834, 2.3534, 3.6519, 2.7831, 5.2873, 4.682, 1.6074, \n .     4.4619, 6.8185, 2.271, 3.7598, 5.615, 2.8965, 2.9879, 1.6102, \n .     6.6407, 3.724, 2.3158, 3.6715, 4.4534, 1.5895, 1.4608, 4.7211, \n .     6.932, 4.0776, 3.6659, 6.27, 5.9853, 6.3361, 1.6582, 4.6947, \n .     2.2616, 1.9047, 1.9976, 2.1007, 4.3665, 1.5894, 5.2119, 3.2628, \n .     8.7921, 4.2392, 7.3967, 5.4007, 3.4952, 1.6334, 3.3317, 2.0635, \n .     8.6966, 7.3172, 4.429, 7.309, 8.7921, 3.6519, 3.3175, 7.6534, \n .     2.872, 1.8209, 2.7778, 1.3567, 1.8195, 4.9671, 1.77, 2.1185, \n .     8.5353, 2.2834, 8.9067, 1.7455, 2.7006, 7.309, 3.3633, 1.8172, \n .     2.3817, 1.1742, 7.8265, 1.1296, 2.5961, 10.7103, 5.4007, \n .     1.618, 6.498, 4.3549, 2.1099, 1.6768, 2.4216, 5.4917, 2.829, \n .     1.9709, 2.4961, 5.2873, 2.3682, 3.7886, 2.1675, 2.5052, 4.5667, \n .     1.7984, 2.072, 1.6686, 3.0993, 2.8237, 2.1329, 3.4145, 3.048, \n .     2.6775, 5.1167, 1.5331, 3.8771, 7.0355, 2.4358, 2.8944, 5.4007, \n .     1.5804, 3.5875, 5.118, 1.5257, 2.0882, 4.9671, 1.5166, 5.6484, \n .     1.7883, 4.0019, 6.0622, 6.4798, 3.3175, 12.1265, 2.1069, \n .     6.2196, 1.4547, 3.9769, 1.7364, 1.8946, 3.5325, 2.4775, 3.4952, \n .     4.148, 3.5549, 2.162, 1.801, 5.5027, 4.2579, 2.4298, 1.1691, \n .     3.0923, 4.175, 1.3163, 1.7573, 1.9682, 2.0063, 2.3053, 3.7979, \n .     3.5459, 2.2565, 1.7523, 5.1167, 5.2873, 2.5806, 7.8148, 4.5667, \n .     8.3248, 2.3552, 2.548, 7.8278, 3.7872, 1.4394, 3.9454, 4.4986, \n .     2.0218, 2.4091, 2.9153, 1.413, 2.4699, 2.1036, 6.6115, 1.3325, \n .     5.9505, 3.2721, 3.615, 8.0136, 2.1705, 2.5403, 6.0622, 2.0788, \n .     4.2673, 3.2157, 7.3197, 2.847, 1.8226, 2.5182, 1.8206), rad = c(1, \n .     5, 5, 4, 24, 24, 5, 3, 24, 3, 7, 24, 3, 4, 24, 24, 4, 5, \n .     4, 5, 4, 5, 5, 5, 24, 5, 6, 4, 24, 2, 24, 24, 6, 5, 24, 5, \n .     4, 3, 24, 5, 24, 24, 4, 3, 24, 1, 4, 2, 3, 5, 4, 24, 7, 2, \n .     24, 5, 24, 4, 24, 5, 5, 4, 4, 3, 24, 4, 4, 8, 5, 24, 5, 6, \n .     1, 24, 24, 5, 4, 5, 4, 24, 5, 5, 4, 5, 4, 24, 4, 4, 7, 24, \n .     8, 24, 5, 7, 4, 24, 5, 1, 5, 5, 24, 24, 5, 6, 3, 24, 5, 8, \n .     8, 24, 4, 4, 24, 24, 4, 1, 6, 5, 5, 1, 5, 3, 4, 4, 4, 3, \n .     4, 24, 8, 6, 24, 5, 3, 1, 24, 5, 24, 1, 6, 8, 4, 8, 3, 5, \n .     24, 4, 6, 5, 3, 24, 6, 7, 7, 7, 7, 6, 5, 4, 24, 24, 24, 4, \n .     24, 24, 3, 24, 24, 2, 5, 5, 2, 1, 4, 3, 4, 5, 8, 5, 4, 24, \n .     5, 4, 2, 2, 5, 24, 4, 7, 24, 8, 4, 2, 24, 24, 5, 3, 5, 1, \n .     1, 4, 2, 4, 3, 5, 4, 24, 24, 24, 6, 24, 3, 1, 7, 4, 24, 5, \n .     4, 6, 8, 24, 4, 4, 24, 4, 8, 4, 4, 5, 24, 3, 5, 1, 24, 24, \n .     8, 4, 24, 5, 5, 8, 4, 4, 2, 5, 6, 24, 5, 24, 24, 24, 24, \n .     3, 24, 5, 4, 1, 4, 7, 4, 2, 24, 24, 24, 5, 6, 3, 2, 1, 8, \n .     5, 3, 5, 4, 5, 24, 24, 2, 24, 4, 4, 5, 7, 5, 3, 2, 5, 24, \n .     6, 24, 7, 24, 5, 4, 4, 5, 4, 4, 4, 24, 5, 7, 3, 5, 24, 4, \n .     24, 5, 1, 24, 5, 5, 24, 4, 24, 24, 5, 2, 8, 6, 4, 24, 4, \n .     6, 24, 8, 4, 24, 4, 4, 5, 24, 2, 5, 4, 4, 4, 3, 5, 4, 5, \n .     5, 1, 24, 4, 5, 5, 4, 6, 2, 8, 5, 5, 5, 4, 4, 24, 24, 2, \n .     4, 24, 5, 24, 2, 24, 4, 24, 6, 24, 4, 4, 24, 8, 5, 5, 24, \n .     6, 5, 4, 4, 4, 4, 24, 6, 5, 24, 4, 24, 4, 24, 5, 8, 4, 3, \n .     24, 24, 3, 5, 4, 8, 3, 3, 4, 24, 24), tax = c(273, 287, 403, \n .     437, 666, 666, 358, 223, 666, 193, 222, 666, 247, 254, 666, \n .     666, 430, 264, 430, 398, 277, 279, 384, 276, 666, 403, 293, \n .     711, 666, 270, 666, 666, 293, 224, 666, 287, 711, 233, 666, \n .     384, 666, 666, 307, 233, 666, 422, 345, 188, 252, 403, 307, \n .     666, 330, 329, 666, 279, 666, 289, 666, 216, 403, 307, 437, \n .     233, 666, 307, 277, 307, 398, 666, 384, 391, 315, 666, 666, \n .     384, 430, 311, 289, 666, 296, 370, 254, 384, 281, 666, 307, \n .     437, 330, 666, 307, 666, 384, 329, 307, 666, 403, 241, 384, \n .     403, 666, 666, 224, 432, 352, 666, 384, 284, 307, 666, 304, \n .     243, 666, 666, 437, 273, 391, 216, 403, 285, 403, 233, 224, \n .     289, 307, 193, 277, 666, 307, 391, 666, 403, 233, 296, 666, \n .     398, 666, 198, 432, 307, 245, 284, 247, 287, 666, 334, 391, \n .     358, 233, 666, 300, 330, 222, 222, 330, 300, 276, 437, 666, \n .     666, 666, 243, 666, 666, 216, 666, 666, 188, 398, 276, 276, \n .     265, 307, 223, 307, 296, 307, 398, 307, 666, 264, 411, 270, \n .     188, 403, 666, 277, 330, 666, 307, 437, 188, 666, 666, 287, \n .     223, 370, 284, 304, 277, 188, 437, 252, 279, 289, 666, 666, \n .     666, 432, 666, 233, 300, 330, 305, 666, 403, 304, 432, 307, \n .     666, 305, 307, 666, 307, 284, 437, 307, 224, 666, 193, 403, \n .     304, 666, 666, 307, 307, 666, 403, 287, 284, 254, 270, 348, \n .     224, 300, 666, 216, 666, 666, 666, 666, 223, 666, 216, 304, \n .     335, 277, 330, 281, 276, 666, 666, 666, 226, 293, 223, 329, \n .     335, 307, 296, 402, 264, 711, 384, 666, 666, 242, 666, 437, \n .     351, 403, 330, 403, 193, 329, 276, 666, 391, 666, 330, 666, \n .     296, 411, 281, 403, 345, 277, 711, 666, 264, 329, 193, 403, \n .     666, 305, 666, 398, 273, 666, 398, 403, 666, 437, 666, 666, \n .     264, 270, 307, 432, 245, 666, 277, 300, 666, 307, 281, 666, \n .     277, 224, 403, 666, 242, 403, 255, 437, 304, 222, 398, 304, \n .     187, 384, 265, 666, 307, 403, 264, 304, 432, 276, 307, 296, \n .     403, 264, 289, 307, 666, 666, 270, 307, 666, 403, 666, 188, \n .     666, 307, 666, 432, 666, 245, 305, 666, 284, 398, 256, 666, \n .     432, 358, 307, 437, 277, 307, 666, 391, 296, 666, 437, 666, \n .     337, 666, 311, 307, 270, 352, 666, 666, 222, 264, 254, 307, \n .     469, 193, 711, 666, 666), ptratio = c(21, 19.6, 14.7, 21.2, \n .     20.2, 20.2, 14.8, 18.6, 20.2, 17.8, 18.4, 20.2, 18.5, 17.6, \n .     20.2, 20.2, 16.9, 13, 16.9, 18.7, 18.6, 19.2, 20.9, 16.4, \n .     20.2, 14.7, 16.6, 20.1, 20.2, 17.8, 20.2, 20.2, 16.6, 20.2, \n .     20.2, 19.6, 20.1, 17.9, 20.2, 20.9, 20.2, 20.2, 21, 17.9, \n .     20.2, 15.9, 18.9, 19.1, 18.3, 14.7, 21, 20.2, 19.1, 12.6, \n .     20.2, 19.2, 20.2, 16, 20.2, 14.9, 14.7, 21, 21.2, 17.9, 20.2, \n .     21, 18.6, 17.4, 15.2, 20.2, 20.9, 19.2, 16.4, 20.2, 20.2, \n .     20.9, 16.9, 15.2, 16, 20.2, 16.6, 17.6, 17.6, 20.9, 19, 20.2, \n .     21, 21.2, 19.1, 20.2, 17.4, 20.2, 20.9, 16.1, 21, 20.2, 14.7, \n .     18.2, 20.9, 14.7, 20.2, 20.2, 20.2, 17.8, 18.8, 20.2, 20.9, \n .     19.7, 17.4, 20.2, 18.4, 16.8, 20.2, 20.2, 21.2, 21, 19.2, \n .     14.9, 14.7, 15.3, 14.7, 17.9, 14.7, 16, 21, 17.8, 18.6, 20.2, \n .     17.4, 19.2, 20.2, 14.7, 17.9, 15.3, 20.2, 18.7, 20.2, 13.6, \n .     17.8, 17.4, 19.2, 19.7, 18.5, 19.6, 20.2, 22, 19.2, 14.8, \n .     17.9, 20.2, 16.6, 19.1, 18.4, 18.4, 19.1, 16.6, 16.4, 21.2, \n .     20.2, 20.2, 20.2, 16.8, 20.2, 20.2, 18.6, 20.2, 20.2, 19.1, \n .     18.7, 16.4, 18, 15.6, 21, 18.6, 21, 16.6, 17.4, 18.7, 21, \n .     20.2, 13, 18.3, 17.8, 19.1, 14.7, 20.2, 18.6, 19.1, 20.2, \n .     17.4, 21.2, 19.1, 20.2, 20.2, 19.6, 18.6, 17.6, 15.5, 16.9, \n .     18.6, 19.1, 21.2, 18.3, 19.2, 16, 20.2, 20.2, 20.2, 17.8, \n .     20.2, 17.9, 15.3, 19.1, 19.2, 20.2, 14.7, 18.4, 17.8, 17.4, \n .     20.2, 19.2, 21, 20.2, 21, 19.7, 21.2, 21, 20.2, 20.2, 17.8, \n .     14.7, 16.9, 20.2, 20.2, 17.4, 21, 20.2, 14.7, 19.6, 19.7, \n .     17.6, 18.2, 14.7, 20.2, 16.6, 20.2, 14.9, 20.2, 20.2, 20.2, \n .     20.2, 18.6, 20.2, 14.9, 18.4, 19.7, 18.6, 19.1, 19, 18, 20.2, \n .     20.2, 20.2, 17.9, 16.6, 18.6, 12.6, 19.7, 17.4, 16.6, 17, \n .     13, 20.1, 20.9, 20.2, 20.2, 17.8, 20.2, 21.2, 17.9, 14.7, \n .     19.1, 14.7, 17.8, 12.6, 16.4, 20.2, 19.2, 20.2, 19.1, 20.2, \n .     16.6, 18.3, 19, 14.7, 18.9, 18.6, 20.1, 20.2, 13, 16.1, 17.8, \n .     14.7, 20.2, 19.2, 20.2, 15.2, 21, 20.2, 15.2, 14.7, 20.2, \n .     21.2, 20.2, 20.2, 13, 17.8, 17.4, 17.8, 19.2, 20.2, 18.6, \n .     16.6, 20.2, 17.4, 19, 20.2, 18.6, 14.7, 14.7, 20.2, 17.8, \n .     14.7, 14.4, 21.2, 18.4, 18.7, 15.2, 18.4, 17, 20.9, 15.6, \n .     20.2, 21, 14.7, 13, 18.4, 17.8, 18, 17.4, 16.6, 14.7, 13, \n .     16, 21, 20.2, 20.2, 17.8, 21, 20.2, 14.7, 20.2, 19.1, 20.2, \n .     21, 20.2, 17.8, 20.2, 19.2, 19.2, 20.2, 19.7, 15.2, 15.1, \n .     20.2, 17.8, 14.8, 21, 21.2, 18.6, 21, 20.2, 19.2, 16.6, 20.2, \n .     21.2, 20.2, 16.1, 20.2, 15.2, 17.4, 18.2, 18.8, 20.2, 20.2, \n .     18.7, 13, 17.6, 17.4, 21.1, 17.8, 20.1, 20.2, 20.2), black = c(393.45, \n .     391.13, 369.3, 396.9, 127.36, 396.9, 368.24, 391.34, 334.4, \n .     392.63, 396.9, 396.9, 396.9, 389.25, 350.65, 9.32, 375.21, \n .     386.86, 382.44, 386.4, 390.94, 377.56, 392.69, 392.8, 354.7, \n .     395.11, 371.72, 390.11, 396.9, 396.9, 18.82, 396.9, 396.9, \n .     396.9, 16.45, 393.68, 344.05, 385.41, 319.98, 393.49, 396.9, \n .     35.05, 390.95, 394.46, 363.02, 389.96, 396.9, 389.15, 395.63, \n .     348.13, 394.33, 396.9, 376.14, 354.31, 396.9, 393.43, 100.63, \n .     396.9, 396.9, 396.9, 364.31, 396.9, 396.9, 389.39, 396.9, \n .     392.53, 396.9, 380.34, 390.49, 392.05, 394.47, 396.9, 392.89, \n .     304.21, 109.85, 70.8, 368.57, 390.5, 396.9, 395.28, 390.96, \n .     387.97, 396.9, 391.23, 390.64, 395.43, 387.94, 388.08, 377.07, \n .     384.97, 391.7, 396.9, 387.69, 390.43, 232.6, 395.69, 356.99, \n .     341.6, 395.58, 396.9, 388.22, 255.23, 396.14, 394.51, 385.64, \n .     28.79, 395.67, 395.58, 396.9, 83.45, 396.42, 395.56, 27.25, \n .     383.32, 394.08, 396.9, 395.77, 392.23, 396.9, 394.72, 330.04, \n .     392.74, 392.78, 396.9, 394.54, 395.56, 385.81, 302.76, 385.05, \n .     396.9, 385.96, 389.61, 383.37, 396.9, 48.45, 386.96, 97.95, \n .     395.52, 344.91, 385.91, 396.9, 395.11, 392.3, 396.9, 291.55, \n .     382.8, 393.29, 371.58, 396.9, 391.98, 394.62, 389.13, 393.68, \n .     393.36, 390.18, 379.41, 396.9, 262.76, 22.01, 393.82, 396.9, \n .     396.9, 386.73, 396.9, 393.24, 318.75, 392.92, 370.31, 373.66, \n .     392.78, 396.9, 393.37, 288.99, 394.96, 360.17, 395.5, 388.45, \n .     394.92, 395.62, 3.5, 387.89, 392.33, 393.55, 377.67, 341.6, \n .     378.38, 394.87, 374.71, 43.06, 377.51, 396.9, 385.02, 240.52, \n .     131.42, 396.9, 388.65, 396.9, 394.74, 362.25, 395.24, 359.29, \n .     385.76, 395.62, 396.9, 392.85, 396.9, 394.43, 390.74, 393.3, \n .     332.09, 396.9, 394.72, 396.9, 376.94, 27.49, 227.61, 396.3, \n .     394.95, 378.95, 272.21, 390.91, 376.88, 329.46, 380.02, 378.08, \n .     396.9, 248.31, 394.81, 393.37, 391, 343.28, 394.02, 370.73, \n .     100.19, 378.35, 306.38, 372.92, 391.71, 396.9, 396.9, 396.9, \n .     395.01, 393.77, 396.9, 391.25, 88.27, 387.31, 396.9, 353.04, \n .     24.65, 349.48, 390.77, 210.97, 377.07, 393.39, 396.9, 381.32, \n .     396.28, 395.63, 391.83, 393.1, 393.07, 3.65, 395.93, 396.9, \n .     396.9, 392.2, 389.85, 360.2, 395.6, 384.3, 390.3, 395.09, \n .     394.76, 375.33, 21.57, 396.9, 396.9, 395.04, 392.43, 240.16, \n .     386.09, 88.01, 394.12, 396.9, 393.74, 396.9, 396.9, 396.9, \n .     393.74, 347.88, 396.9, 370.78, 396.9, 372.8, 396.21, 389.43, \n .     396.9, 396.9, 384.54, 395.75, 396.9, 374.43, 6.68, 377.17, \n .     385.09, 393.87, 396.9, 391.34, 396.9, 338.92, 318.01, 392.04, \n .     395.33, 396.9, 384.07, 396.06, 395.24, 395.59, 396.9, 396.9, \n .     393.25, 372.75, 50.92, 382, 396.9, 396.9, 348.93, 390.55, \n .     351.85, 81.33, 392.83, 169.27, 394.23, 392.11, 396.23, 394.63, \n .     377.68, 396.9, 384.46, 394.05, 376.7, 314.64, 396.9, 88.63, \n .     383.29, 395.21, 338.63, 393.53, 390.07, 393.23, 388.45, 389.7, \n .     396.9, 386.75, 352.58, 366.15, 392.18, 376.73, 396.9, 353.89, \n .     60.72, 379.38, 396.21, 376.57, 392.68, 388.74, 316.03, 396.9, \n .     383.73, 10.48, 390.68, 382.84, 392.9, 355.29, 396.9, 390.86, \n .     358.77, 396.9, 393.63, 386.85, 2.52, 396.9, 391.27, 2.6, \n .     388.69, 380.79, 396.9, 375.52, 396.9, 390.39, 396.9, 364.61, \n .     379.7, 331.29, 396.9, 393.42, 396.9, 372.08, 396.9, 396.9, \n .     318.43, 374.56, 68.95), lstat = c(6.48, 11.74, 3.7, 15.39, \n .     26.64, 16.29, 4.97, 13.65, 14.13, 4.45, 6.47, 10.74, 9.62, \n .     6.05, 14.19, 26.45, 7.34, 5.91, 9.97, 12.34, 16.03, 11.41, \n .     12.33, 13.51, 7.12, 11.64, 9.51, 18.07, 21.08, 5.5, 14.52, \n .     13.99, 7.6, 9.74, 20.62, 5.08, 23.97, 4.84, 15.7, 13, 19.77, \n .     21.22, 11.28, 7.44, 23.24, 8.65, 8.79, 14.37, 4.32, 12.03, \n .     16.3, 37.97, 10.15, 8.61, 21.24, 10.13, 15.17, 15.84, 20.85, \n .     4.85, 7.39, 8.26, 18.34, 9.55, 20.32, 13.83, 10.87, 3.76, \n .     2.87, 2.96, 13.44, 14.33, 6.57, 19.31, 23.27, 10.63, 9.09, \n .     15.71, 6.27, 7.01, 5.33, 4.61, 7.19, 15.55, 7.51, 11.48, \n .     12.8, 24.16, 3.59, 22.98, 9.71, 13.22, 14.09, 4.86, 27.71, \n .     16.59, 28.32, 12.93, 7.67, 29.29, 11.45, 16.42, 8.51, 10.3, \n .     10.53, 34.37, 18.66, 9.5, 7.6, 17.64, 11.5, 13.45, 29.05, \n .     13.11, 14.59, 9.08, 15.1, 4.59, 26.82, 7.85, 11.32, 18.8, \n .     3.81, 10.4, 19.88, 7.56, 9.38, 24.1, 4.14, 14.1, 19.52, 1.92, \n .     5.81, 4.98, 22.74, 10.27, 12.03, 3.16, 15.76, 2.47, 4.7, \n .     13.15, 6.53, 6.15, 14.1, 8.05, 17.6, 4.74, 30.81, 17.12, \n .     12.4, 18.46, 6.93, 8.93, 9.16, 6.36, 17.92, 17.31, 17.15, \n .     10.29, 16.35, 5.28, 18.85, 26.77, 8.05, 15.02, 10.42, 25.41, \n .     11.97, 9.69, 4.21, 5.03, 11.69, 7.73, 22.6, 9.04, 9.54, 6.78, \n .     8.47, 16.94, 8.1, 7.79, 8.2, 14.27, 13.28, 18.76, 10.97, \n .     9.52, 23.98, 3.92, 18.46, 14.81, 23.79, 13.33, 12.79, 13, \n .     7.18, 5.49, 7.83, 23.98, 27.26, 11.12, 1.98, 9.68, 7.39, \n .     30.59, 17.11, 12.67, 12.04, 12.13, 16.2, 8.23, 3.54, 9.88, \n .     18.05, 12.14, 11.72, 16.21, 3.95, 16.23, 5.52, 14.81, 27.38, \n .     10.26, 14.44, 12.26, 20.34, 10.56, 14.36, 13.98, 12.12, 12.43, \n .     13.34, 16.22, 11.65, 17.28, 30.62, 29.53, 6.12, 9.22, 3.53, \n .     8.16, 7.43, 8.01, 11.38, 36.98, 3.76, 18.13, 14.64, 15.69, \n .     24.91, 6.58, 20.08, 3.01, 7.9, 5.98, 14.66, 5.9, 7.22, 11.34, \n .     19.92, 7.74, 17.16, 4.81, 7.14, 6.59, 6.62, 5.89, 8.05, 6.29, \n .     4.45, 3.16, 18.06, 9.42, 3.73, 25.79, 9.14, 25.68, 12.6, \n .     6.36, 9.81, 3.53, 15.02, 4.82, 4.08, 10.5, 22.88, 13.59, \n .     34.77, 6.56, 8.88, 14.69, 5.49, 6.72, 14.1, 8.1, 18.06, 13.35, \n .     19.37, 7.44, 9.5, 5.04, 1.73, 18.71, 7.54, 17.27, 6.68, 5.64, \n .     13.27, 5.39, 5.5, 17.79, 21.32, 12.87, 14.76, 14.79, 5.7, \n .     21.46, 10.16, 3.33, 24.56, 17.27, 11.22, 18.13, 4.63, 5.29, \n .     23.6, 29.55, 2.88, 21.45, 19.69, 4.03, 16.65, 2.97, 17.19, \n .     12.73, 2.94, 5.1, 4.54, 4.5, 16.47, 4.38, 26.4, 18.72, 16.14, \n .     7.79, 10.36, 15.37, 3.57, 4.73, 10.11, 3.32, 5.12, 8.58, \n .     14.67, 18.14, 9.53, 8.81, 13.04, 13.44, 6.43, 24.08, 17.58, \n .     18.68, 21.02, 14.98, 10.45, 14, 3.56, 6.72, 19.01, 6.86, \n .     4.56, 3.95, 17.73, 17.09, 6.07, 18.35, 34.41, 9.47, 6.58, \n .     23.29, 12.92, 6.92, 10.11, 15.03, 10.19, 4.67, 3.26, 19.15, \n .     9.93, 10.59, 12.67, 18.03, 21.32, 5.33, 11.25, 2.98, 6.36, \n .     14.8, 5.68, 29.68, 7.79, 34.02)), row.names = c(\"505\", \"324\", \n . \"167\", \"129\", \"418\", \"471\", \"299\", \"270\", \"466\", \"187\", \"307\", \n . \"481\", \"85\", \"277\", \"362\", \"438\", \"330\", \"263\", \"329\", \"79\", \n . \"213\", \"37\", \"105\", \"217\", \"366\", \"165\", \"290\", \"492\", \"382\", \n . \"89\", \"428\", \"463\", \"289\", \"340\", \"419\", \"326\", \"490\", \"42\", \n . \"422\", \"111\", \"404\", \"412\", \"20\", \"44\", \"377\", \"343\", \"70\", \"121\", \n . \"40\", \"172\", \"25\", \"375\", \"248\", \"198\", \"378\", \"39\", \"435\", \"298\", \n . \"390\", \"280\", \"160\", \"14\", \"130\", \"45\", \"402\", \"22\", \"206\", \"230\", \n . \"193\", \"371\", \"104\", \"501\", \"255\", \"450\", \"436\", \"103\", \"331\", \n . \"13\", \"296\", \"483\", \"176\", \"345\", \"279\", \"110\", \"84\", \"359\", \n . \"29\", \"141\", \"252\", \"406\", \"221\", \"465\", \"108\", \"304\", \"33\", \n . \"443\", \"149\", \"287\", \"102\", \"145\", \"488\", \"461\", \"339\", \"118\", \n . \"346\", \"413\", \"107\", \"64\", \"224\", \"431\", \"316\", \"51\", \"416\", \n . \"480\", \"138\", \"503\", \"500\", \"282\", \"143\", \"285\", \"170\", \"48\", \n . \"204\", \"295\", \"24\", \"181\", \"214\", \"476\", \"225\", \"498\", \"442\", \n . \"163\", \"43\", \"1\", \"420\", \"78\", \"433\", \"284\", \"116\", \"233\", \"293\", \n . \"61\", \"86\", \"327\", \"423\", \"355\", \"496\", \"300\", \"49\", \"396\", \"242\", \n . \"246\", \"305\", \"306\", \"247\", \"239\", \"219\", \"135\", \"467\", \"464\", \n . \"395\", \"53\", \"444\", \"401\", \"65\", \"421\", \"484\", \"124\", \"77\", \"218\", \n . \"98\", \"194\", \"19\", \"273\", \"31\", \"174\", \"237\", \"75\", \"16\", \"458\", \n . \"265\", \"353\", \"92\", \"122\", \"152\", \"392\", \"207\", \"249\", \"446\", \n . \"229\", \"140\", \"126\", \"445\", \"368\", \"328\", \"271\", \"344\", \"342\", \n . \"333\", \"212\", \"127\", \"133\", \"41\", \"36\", \"297\", \"399\", \"391\", \n . \"360\", \"117\", \"408\", \"50\", \"286\", \"254\", \"72\", \"437\", \"168\", \n . \"313\", \"113\", \"234\", \"459\", \"73\", \"27\", \"405\", \"15\", \"62\", \"132\", \n . \"35\", \"338\", \"473\", \"185\", \"153\", \"332\", \"485\", \"434\", \"231\", \n . \"28\", \"389\", \"148\", \"325\", \"60\", \"275\", \"93\", \"202\", \"336\", \"241\", \n . \"415\", \"281\", \"449\", \"364\", \"427\", \"478\", \"274\", \"414\", \"283\", \n . \"314\", \"351\", \"209\", \"251\", \"82\", \"97\", \"398\", \"482\", \"425\", \n . \"56\", \"288\", \"272\", \"199\", \"350\", \"235\", \"178\", \"201\", \"269\", \n . \"489\", \"101\", \"370\", \"417\", \"2\", \"393\", \"131\", \"348\", \"166\", \n . \"253\", \"156\", \"183\", \"197\", \"220\", \"440\", \"495\", \"374\", \"250\", \n . \"373\", \"173\", \"352\", \"83\", \"151\", \"68\", \"208\", \"493\", \"397\", \n . \"268\", \"302\", \"180\", \"162\", \"455\", \"74\", \"453\", \"188\", \"504\", \n . \"358\", \"190\", \"161\", \"447\", \"139\", \"472\", \"470\", \"267\", \"90\", \n . \"222\", \"112\", \"291\", \"384\", \"211\", \"243\", \"456\", \"226\", \"81\", \n . \"383\", \"215\", \"205\", \"150\", \"432\", \"3\", \"147\", \"196\", \"128\", \n . \"320\", \"4\", \"191\", \"309\", \"354\", \"106\", \"195\", \"409\", \"23\", \"157\", \n . \"259\", \"319\", \"119\", \"99\", \"238\", \"177\", \"164\", \"258\", \"294\", \n . \"18\", \"475\", \"372\", \"91\", \"32\", \"376\", \"159\", \"430\", \"125\", \"477\", \n . \"21\", \"487\", \"115\", \"367\", \"292\", \"71\", \"457\", \"59\", \"189\", \"58\", \n . \"452\", \"114\", \"301\", \"34\", \"142\", \"216\", \"17\", \"424\", \"499\", \n . \"179\", \"411\", \"134\", \"363\", \"66\", \"369\", \"8\", \"223\", \"95\", \"347\", \n . \"479\", \"468\", \"5\", \"264\", \"276\", \"228\", \"55\", \"184\", \"491\", \"361\", \n . \"439\"), class = \"data.frame\"), y = c(22, 18.5, 50, 18, 10.4, \n . 19.9, 22.5, 20.7, 19.9, 50, 33.4, 23, 23.9, 33.2, 19.9, 8.7, \n . 22.6, 48.8, 19.3, 21.2, 22.4, 20, 20.1, 23.3, 27.5, 22.7, 24.8, \n . 13.6, 10.9, 23.6, 10.9, 19.5, 22.3, 19, 8.8, 24.6, 7, 26.6, 14.2, \n . 21.7, 8.3, 17.2, 18.2, 24.7, 13.9, 16.5, 20.9, 22, 30.8, 19.1, \n . 15.6, 13.8, 20.5, 30.3, 13.3, 24.7, 11.7, 20.3, 11.5, 35.1, 23.3, \n . 20.4, 14.3, 21.2, 7.2, 19.6, 22.6, 31.5, 36.4, 50, 19.3, 16.8, \n . 21.9, 13, 13.4, 18.6, 19.8, 21.7, 28.6, 25, 29.4, 31.2, 29.1, \n . 19.4, 22.9, 22.7, 18.4, 14, 24.8, 5, 26.7, 21.4, 20.4, 33.1, \n . 13.2, 18.4, 17.8, 20.1, 26.5, 11.8, 20.6, 16.4, 20.6, 19.2, 17.5, \n . 17.9, 19.5, 25, 30.1, 14.5, 16.2, 19.7, 7.2, 21.4, 17.1, 20.6, \n . 17.5, 35.4, 13.4, 32.2, 22.3, 16.6, 48.5, 21.7, 14.5, 39.8, 28.1, \n . 13.3, 44.8, 18.3, 17.1, 50, 25.3, 24, 8.4, 20.8, 16.1, 50, 18.3, \n . 41.7, 27.9, 18.7, 26.6, 23, 20.8, 18.2, 23.1, 29, 14.4, 13.1, \n . 20.1, 18.5, 36.1, 28.4, 24.3, 23.7, 21.5, 15.6, 19, 20.2, 12.7, \n . 25, 15.4, 5.6, 33, 16.7, 21.8, 17.3, 20, 28.7, 38.7, 31.1, 20.2, \n . 24.4, 12.7, 23.6, 25.1, 24.1, 19.9, 13.5, 36.5, 18.6, 22, 20.3, \n . 19.6, 23.2, 24.4, 24.5, 11.8, 46.7, 17.8, 21.4, 10.8, 23.1, 22.2, \n . 21.1, 23.9, 32.7, 19.4, 19.3, 15.7, 23, 34.9, 18.9, 27.1, 5, \n . 15.1, 22.6, 21.2, 27.9, 19.4, 22, 42.8, 21.7, 9.6, 23.8, 19.4, \n . 18.8, 48.3, 14.9, 22.8, 16.6, 8.5, 18.2, 16, 19.6, 13.5, 18.5, \n . 23.2, 26.4, 15.3, 17.1, 20.6, 14.3, 24.3, 14.8, 10.2, 14.6, 25, \n . 19.6, 32.4, 22.9, 24.1, 21.1, 22, 7, 45.4, 14.1, 16.8, 10.2, \n . 12, 35.2, 16.3, 46, 21.6, 22.9, 24.4, 24.4, 23.9, 21.4, 8.5, \n . 23.7, 11.7, 35.4, 23.2, 25.2, 34.6, 26.6, 29, 24.6, 32.9, 43.5, \n . 15.2, 27.5, 50, 7.5, 21.6, 9.7, 19.2, 23.1, 25, 29.6, 15.6, 37.9, \n . 33.3, 23, 12.8, 24.5, 13.8, 26.2, 50, 23.1, 24.1, 24.8, 21.5, \n . 22, 22.5, 20.1, 12.5, 50, 22, 37.2, 50, 14.9, 23.4, 16.1, 32, \n . 23.9, 21.7, 34.9, 27, 14.9, 13.3, 19.6, 20.1, 30.7, 28.7, 21.7, \n . 22.8, 28.5, 12.3, 21.7, 22.2, 14.1, 50, 28, 11.3, 23.7, 50, 15.4, \n . 14.1, 34.7, 15.6, 50, 16.2, 21, 33.4, 37, 22.8, 30.1, 19.5, 29.1, \n . 17.2, 15.2, 13.1, 36, 23.1, 20.4, 43.8, 31.5, 23.2, 50, 50, 23.9, \n . 17.5, 13.8, 50, 22.6, 14.5, 15, 24.3, 9.5, 18.8, 16.7, 13.6, \n . 19.1, 18.5, 21.9, 37.3, 24.2, 12.7, 23.3, 29.8, 31.6, 15.2, 18.7, \n . 24.8, 13.1, 14.4, 25, 23.1, 13.4, 21.2, 29.9, 15, 18.4, 20.8, \n . 23.5, 50, 27.1, 27.5, 20.6, 17.2, 14.6, 19.1, 36.2, 31, 32, 31.6, \n . 18.9, 32.5, 8.1, 25, 8.4), neurons = 32, epochs = 200)",
      "7. input %>% layer_dense_features(dense_features(spec)) %>% layer_dense(units = neurons, \n .     activation = \"relu\") %>% layer_dense(units = neurons, activation = \"relu\") %>% \n .     layer_dense(units = 1)",
      "8. layer_dense(., units = 1)",
      "9. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n .     name = name, trainable = trainable, weights = weights))",
      "10. layer_dense(., units = neurons, activation = \"relu\")",
      "11. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n  .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n  .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n  .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n  .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n  .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n  .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n  .     name = name, trainable = trainable, weights = weights))",
      "12. layer_dense(., units = neurons, activation = \"relu\")",
      "13. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n  .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n  .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n  .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n  .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n  .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n  .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n  .     name = name, trainable = trainable, weights = weights))",
      "14. layer_dense_features(., dense_features(spec))",
      "15. dense_features(spec)",
      "16. spec$dense_features()",
      "17. stop(\"Only available after fitting the feature_spec.\")"
     ]
    }
   ],
   "source": [
    "# do not set neurons and epochs for hyperparameter optimization\n",
    "# you can also set a range for them  \n",
    "train_test(regression_cnn(\"medv\", neurons=32,epochs=200), boston_train, boston_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
